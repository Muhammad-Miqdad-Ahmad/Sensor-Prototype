
Analyzing model 
/home/cyber-surge/STM32Cube/Repository//Packs/STMicroelectronics/X-CUBE-AI/10.2.0/Utilities/linux/stedgeai analyze --target stm32l4 --name harsh_detection_prototype -m /home/cyber-surge/Work/Uni/Final Year Project /Sensor-Prototype/accelerometer/model.tflite --compression none --verbosity 1 --workspace /tmp/mxAI_workspace1043029343198811360265942709000340 --output /home/cyber-surge/.stm32cubemx/harsh_detection_prototype_output 
ST Edge AI Core v2.2.0-20266 2adc00962 
                                                         
Creating c (debug) info json file /home/cyber-surge/.stm32cubemx/harsh_detection_prototype_output/harsh_detection_prototype_c_info.json 
  
 Exec/report summary (analyze) 
 ---------------------------------------------------------------------------------------------------------------------------- 
 model file         :   /home/cyber-surge/Work/Uni/Final Year Project /Sensor-Prototype/accelerometer/model.tflite            
 type               :   tflite                                                                                                
 c_name             :   harsh_detection_prototype                                                                             
 compression        :   none                                                                                                  
 options            :   allocate-inputs, allocate-outputs                                                                     
 optimization       :   balanced                                                                                              
 target/series      :   stm32l4                                                                                               
 workspace dir      :   /tmp/mxAI_workspace1043029343198811360265942709000340                                                 
 output dir         :   /home/cyber-surge/.stm32cubemx/harsh_detection_prototype_output                                       
 model_fmt          :   ss/sa per channel                                                                                     
 model_name         :   model                                                                                                 
 model_hash         :   0x0567c223e09c17f2e1f5f854ee6bc063                                                                    
 params #           :   11,493 items (11.71 KiB)                                                                              
 ---------------------------------------------------------------------------------------------------------------------------- 
 input 1/1          :   'serving_default_input_layer0', int8(1x40x6), 240 Bytes, QLinear(0.119718373,25,int8), activations    
 output 1/1         :   'nl_16', int8(1x5), 5 Bytes, QLinear(0.003906250,-128,int8), activations                              
 macc               :   137,904                                                                                               
 weights (ro)       :   11,988 B (11.71 KiB) (1 segment) / -33,984(-73.9%) vs float model                                     
 activations (rw)   :   8,096 B (7.91 KiB) (1 segment) *                                                                      
 ram (total)        :   8,096 B (7.91 KiB) = 8,096 + 0 + 0                                                                    
 ---------------------------------------------------------------------------------------------------------------------------- 
 (*) 'input'/'output' buffers are allocated in the activations buffer 
                                                         
Computing AI RT data/code size (target=stm32l4).. 
                                                         
 Model name - model 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 m_id   layer (original)                  oshape                param/size         macc                   connected to 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 0      serving_default_input_layer0 ()   [b:1,h:40,c:6] 
        reshape_0 (EXPAND_DIMS)           [b:1,h:1,w:40,c:6]                              serving_default_input_layer0 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 1      conv2d_1 (CONV_2D)                [b:1,h:1,w:38,c:32]   608/704          21,920                      reshape_0 
        nl_1_nl (CONV_2D)                 [b:1,h:1,w:38,c:32]                     1,216                       conv2d_1 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 2      tfl_pseudo_qconst9 ()             [b:32]                32/32 
        eltwise_2 (MUL)                   [b:1,h:1,w:38,c:32]                     1,216                        nl_1_nl 
                                                                                                    tfl_pseudo_qconst9 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 3      tfl_pseudo_qconst8 ()             [b:32]                32/32 
        eltwise_3 (ADD)                   [b:1,h:1,w:38,c:32]                     1,216                      eltwise_2 
                                                                                                    tfl_pseudo_qconst8 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 4      reshape_4 (RESHAPE)               [b:1,h:38,c:32]                                                    eltwise_3 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 5      reshape_5 (EXPAND_DIMS)           [b:1,h:1,w:38,c:32]                                                reshape_4 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 6      pool_6 (MAX_POOL_2D)              [b:1,h:1,w:19,c:32]                     1,216                      reshape_5 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 7      reshape_7 (RESHAPE)               [b:1,h:19,c:32]                                                       pool_6 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 8      reshape_8 (EXPAND_DIMS)           [b:1,h:1,w:19,c:32]                                                reshape_7 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 9      conv2d_9 (CONV_2D)                [b:1,h:1,w:17,c:64]   6,208/6,400     104,512                      reshape_8 
        nl_9_nl (CONV_2D)                 [b:1,h:1,w:17,c:64]                     1,088                       conv2d_9 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 10     tfl_pseudo_qconst5 ()             [b:64]                64/64 
        eltwise_10 (MUL)                  [b:1,h:1,w:17,c:64]                     1,088                        nl_9_nl 
                                                                                                    tfl_pseudo_qconst5 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 11     tfl_pseudo_qconst4 ()             [b:64]                64/64 
        eltwise_11 (ADD)                  [b:1,h:1,w:17,c:64]                     1,088                     eltwise_10 
                                                                                                    tfl_pseudo_qconst4 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 12     reshape_12 (RESHAPE)              [b:1,h:17,c:64]                                                   eltwise_11 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 13     pool_13 (MEAN)                    [b:1,h:1,c:64]                          1,088                     reshape_12 
        reshape_13_reshape (MEAN)         [b:1,c:64]                                                           pool_13 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 14     tfl_pseudo_qconst3 ()             [b:64,c:64]           4,096/4,096 
        tfl_pseudo_qconst2 ()             [b:64]                64/256 
        gemm_14 (FULLY_CONNECTED)         [b:1,c:64]                              4,160             reshape_13_reshape 
                                                                                                    tfl_pseudo_qconst3 
                                                                                                    tfl_pseudo_qconst2 
        nl_14_nl (FULLY_CONNECTED)        [b:1,c:64]                                 64                        gemm_14 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 15     tfl_pseudo_qconst1 ()             [b:5,c:64]            320/320 
        tfl_pseudo_qconst ()              [b:5]                 5/20 
        gemm_15 (FULLY_CONNECTED)         [b:1,c:5]                                 325                       nl_14_nl 
                                                                                                    tfl_pseudo_qconst1 
                                                                                                     tfl_pseudo_qconst 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 16     nl_16 (SOFTMAX)                   [b:1,c:5]                                  75                        gemm_15 
 ------ --------------------------------- --------------------- ------------- --------- ------------------------------ 
 model: macc=140,272 weights=11,988 activations=-- io=-- 
                                                         
 Number of operations per c-layer 
 ------- ------ -------------------------- --------- ------------ 
 c_id    m_id   name (type)                      #op         type 
 ------- ------ -------------------------- --------- ------------ 
 0       1      conv2d_1 (Conv2D)             21,920   smul_s8_s8 
 1       2      eltwise_2 (Eltwise/mul)        1,216     op_s8_s8 
 2       3      eltwise_3 (Eltwise/add)        1,216     op_s8_s8 
 3       6      pool_6 (Pool)                  1,216   smul_s8_s8 
 4       9      conv2d_9 (Conv2D)            104,512   smul_s8_s8 
 5       10     eltwise_10 (Eltwise/mul)       1,088     op_s8_s8 
 6       11     eltwise_11 (Eltwise/add)       1,088     op_s8_s8 
 7       13     pool_13 (Pool)                 1,088   smul_s8_s8 
 8       14     gemm_14 (Dense)                4,160   smul_s8_s8 
 9       15     gemm_15 (Dense)                  325   smul_s8_s8 
 10      16     nl_16 (Nonlinearity)              75     op_s8_s8 
 ------- ------ -------------------------- --------- ------------ 
 total                                       137,904 
                                                         
 Number of operation types 
 ---------------- --------- ----------- 
 operation type           #           % 
 ---------------- --------- ----------- 
 smul_s8_s8         133,221       96.6% 
 op_s8_s8             4,683        3.4% 
                                                         
 Complexity report (model) 
 ------ -------------------- ------------------------- ------------------------- ------ 
 m_id   name                 c_macc                    c_rom                     c_id 
 ------ -------------------- ------------------------- ------------------------- ------ 
 1      conv2d_1             ||||              15.9%   ||                 5.9%   [0] 
 2      tfl_pseudo_qconst9   |                  0.9%   |                  0.3%   [1] 
 3      tfl_pseudo_qconst8   |                  0.9%   |                  0.3%   [2] 
 6      pool_6               |                  0.9%   |                  0.0%   [3] 
 9      conv2d_9             ||||||||||||||||  75.8%   ||||||||||||||||  53.4%   [4] 
 10     tfl_pseudo_qconst5   |                  0.8%   |                  0.5%   [5] 
 11     tfl_pseudo_qconst4   |                  0.8%   |                  0.5%   [6] 
 13     pool_13              |                  0.8%   |                  0.0%   [7] 
 14     tfl_pseudo_qconst3   |                  3.0%   |||||||||||       36.3%   [8] 
 15     tfl_pseudo_qconst1   |                  0.2%   |                  2.8%   [9] 
 16     nl_16                |                  0.1%   |                  0.0%   [10] 
 ------ -------------------- ------------------------- ------------------------- ------ 
 macc=137,904 weights=11,988 act=8,096 ram_io=0 
                                                         
 Requested memory size by section - "stm32l4" target 
 ---------------------------------- -------- -------- ------- ------- 
 module                                 text   rodata    data     bss 
 ---------------------------------- -------- -------- ------- ------- 
 NetworkRuntime1020_CM4_GCC.a         30,220        0       0       0 
 harsh_detection_prototype.o             804    1,341   3,720     228 
 harsh_detection_prototype_data.o         48       16      88       0 
 lib (toolchain)*                      2,120        0       0       0 
 ---------------------------------- -------- -------- ------- ------- 
 RT total**                           33,192    1,357   3,808     228 
 ---------------------------------- -------- -------- ------- ------- 
 weights                                   0   11,992       0       0 
 activations                               0        0       0   8,096 
 io                                        0        0       0       0 
 ---------------------------------- -------- -------- ------- ------- 
 TOTAL                                33,192   13,349   3,808   8,324 
 ---------------------------------- -------- -------- ------- ------- 
 *  toolchain objects (libm/libgcc*) 
 ** RT AI runtime objects (kernels+infrastructure) 
                                                         
  Summary - "stm32l4" target 
  --------------------------------------------------- 
               FLASH (ro)      %*   RAM (rw)       % 
  --------------------------------------------------- 
  RT total         38,357   76.2%      4,036   33.3% 
  --------------------------------------------------- 
  TOTAL            50,349             12,132 
  --------------------------------------------------- 
  *  rt/total 
                                                         
Creating txt report file /home/cyber-surge/.stm32cubemx/harsh_detection_prototype_output/harsh_detection_prototype_analyze_report.txt 
elapsed time (analyze): 10.536s 
Model file:      model.tflite 
Total Flash:     50345 B (49.17 KiB) 
    Weights:     11988 B (11.71 KiB) 
    Library:     38357 B (37.46 KiB) 
Total Ram:       12132 B (11.85 KiB) 
    Activations: 8096 B (7.91 KiB) 
    Library:     4036 B (3.94 KiB) 
    Input:       240 B (included in Activations) 
    Output:      5 B (included in Activations) 
Done